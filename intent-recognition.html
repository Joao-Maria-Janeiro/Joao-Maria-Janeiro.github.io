<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <title></title>
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link rel="stylesheet" href="https://cdn.rawgit.com/konpa/devicon/df6431e323547add1b4cf45992913f15286456d3/devicon.min.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

    <style media="screen">
    .pimg1{
      background-image:url(img/landing.jpg);
      width: 100%;
      height: 200px;
    }
    .tittlez{
      text-align: center;
    }
    .pimg1 {
    position: relative;
    }
    .ptext {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
    }

    .ptext h3, p{
      color: #000000;
    }

    .topz{
      margin-top: 100px;
    }

    @media screen and (max-width: 960px) {
      .first {
        margin-top: 200px;
      }
      .topz{
        margin-top: 0px;
      }
      .topz img{
        margin-top: 100px;
      }
      .card{
        margin-left: 50px;
      }
    }

    h1 {
      text-align:center;
    }

    h2 {
      text-align:center;
    }

    h3 {
      text-align:center;
    }

    img {
      margin-left: auto;
      margin-right: auto;
      display: block;
    }

    </style>
  </head>
  <body>

    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
      <a class="navbar-brand" href="index.html">
        <img class="rounded-circle" src="./img/profile.jpg" width="40" height="40" alt="">
      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav mr-auto">
          <li class="nav-item">
            <a class="nav-link" href="projects.html">Projects</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="experiences.html">Experiences</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="writings.html">Writings</a>
          </li>
        </ul>
      </div>
    </nav>


  <br><br>
  <div class="container">

    <h1 id="buildinganintentrecognitionsystem">Building an intent recognition system</h1>

    <h2 id="shortdescription">Short Description</h2>

    <p>With this project the objective was, given an user input ,recognize what the user intent was, this system is only able to recognize between 4 inputs: greeting, goodbye, price and images. We could feed it more data and make it able to recognize more intents but that was not the main focus of the project.</p>

    <p>We were able to predict the intent quite well given our really small <a href="https://github.com/Joao-Maria-Janeiro/Intent-Recognition/blob/master/intents.json">dataset</a>. Since just recognizing the intent is not the funniest, we built a little chat bot around it, as this is one of the intent recognition's main applications. Our bot is able to get price and images of shoes contained <a href="https://github.com/Joao-Maria-Janeiro/Intent-Recognition/blob/master/7004_1.csv">here</a>, you say the brand and it will give you all the options for that brand, we could have done the product name instead of the brand but some of those names are quite big and complex so the brand was easy enough for the demonstration purpose.</p>

    <h2 id="technologiesthatwillbeused">Technologies that will be used</h2>

    <p>For this project Tensorflow is going to be the main weapon of choice.
    The technologies used:</p>

    <ul>
    <li>numpy</li>

    <li>nltk</li>

    <li>pandas</li>

    <li>json</li>

    <li>tensorflow</li>

    <li>keras</li>
    </ul>

    <h2 id="parameterschoices">Parameters choices</h2>

    <h3 id="datapreprocessingcodehttpsgithubcomjoaomariajaneirointentrecognitionblobmasterdata_handlerpy">Data preprocessing - <a href="https://github.com/Joao-Maria-Janeiro/Intent-Recognition/blob/master/data_handler.py">code</a></h3>

    <p>For this project, since our dataset is quite small, using an implementation such as word2vec or BERT would not have the best performance as those methods require a lot of data, so... We will use our trusty friend Bag Of Words. Although bag of words is not very good as it does not save any relationship between words nor does it handle words out of vocabulary well, with our really small dataset it is still our best option.</p>

    <p>Alright so how will we build this bag of words? First of all we will lemmatize our data using nltk's WordNetLemmatizer, in case you are unfamiliar with lemmatization, it's a technique used to remove inflectional endings and return the base word of a given word (e.g: churches -> church; dogs -> dog; am, are, is -> be ). This is handy as we do not want our results to change based on how the user will conjugate the words, with this lemmatization we remove this issue. We will also make our system case insensitive converting all words to lowercase and also remove all stop words. </p>

    <p>After this word play is done, as you know our model only takes numbers as inputs so it is time to convert our sentences into vectors. To do so we will use sklearn's TfidfVectorizer, if you don't know what Tf-Idf is, it's bag of words but instead of saving 1 in the word positions it's saves the number of occurrences, this is important as some repeated words might have more meaning.
    Example:
    Let's assume our dictionary are the words "are", "cat", "dog", "is", "the", "crazy", "beautiful", "gorgeous", "cute".
    Given the sentence: "The cat is cute", our bag of words and tf-idf vector would be [010110001]
    but given the sentence "The cat is cute and the cat is gorgeous",
    our bow vector would be: [010110011], but the tf-idf would be [020220011].
     This Tf-IDF vectorizer will use 1-grams (unigrams) and 2-grams (bigrams), so our vectorizer will create vectorizations for single words and for pairs of words, this is good as some pairs of words have more meaning together than apart, we could use larger n-grams but this would not give us much better accuracy.</p>

    <h3 id="themodelcodehttpsgithubcomjoaomariajaneirointentrecognitionblobmastermainpy">The model - <a href="https://github.com/Joao-Maria-Janeiro/Intent-Recognition/blob/master/main.py">Code</a></h3>

    <p>For the model we will simply use 3 densely connected layers, the input layer, the middle layer with the rectified linear unit activation function and with 2/3 input nodes + output nodes (a generally good option) and finally the output layer with, you probably guessed it, softmax activation function. </p>

    <p>For the compiler we will use Adam as it is the most common, the loss function is softmax cross entropy as this is a multi layer output and for metrics we will use accuracy. </p>

    <h2 id="conclusions">Conclusions</h2>

    <p>Our model is quite fragile to words out of vocabulary (words that it has never seen in it's dataset), this and the whole model's performance could really see a lot of benefits from an approach like word2vec or BERT as I mentioned before, but for this we would need a lot more data so, really, the thing that could really improve this project significantly would be having more data and, with that, change our tf-idf to a BERT approach.</p>
  </div>


  <footer> <center>
    <a style="color:gray;" href="https://github.com/Joao-Maria-Janeiro"><i style="font-size: 1.6em;" class="fab fa-github"></i></a>
    <a style="color:gray;" href="https://www.linkedin.com/in/joaomariajaneiro/"><i style="font-size: 1.6em;" class="fab fa-linkedin"></i></a>
  </center></footer>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
  <script type="text/javascript" src="https://platform.linkedin.com/badges/js/profile.js" async defer></script>
  <script defer src="https://use.fontawesome.com/releases/v5.7.2/js/all.js" integrity="sha384-0pzryjIRos8mFBWMzSSZApWtPl/5++eIfzYmTgBBmXYdhvxPc+XcFEk+zJwDgWbP" crossorigin="anonymous"></script>
    </body>
  </html>
